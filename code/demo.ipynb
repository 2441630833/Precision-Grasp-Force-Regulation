{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "24b767a4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-18T06:51:54.135290Z",
     "start_time": "2024-02-18T06:51:54.130292Z"
    }
   },
   "outputs": [],
   "source": [
    "import logging\n",
    "import can\n",
    "from time import sleep\n",
    "\n",
    "# Initialize logging\n",
    "logging.basicConfig(\n",
    "    level=logging.ERROR, format=\"%(asctime)s - %(levelname)s - %(message)s\"\n",
    ")\n",
    "\n",
    "# Initialize the CAN bus\n",
    "bus = can.interface.Bus(interface=\"pcan\", channel=\"PCAN_USBBUS1\", bitrate=1000000)\n",
    "########################################\n",
    "# Import the CAN bus libraries for the gripper and Xiaomi micro motor\n",
    "########################################\n",
    "from gripper_control import GripperControl\n",
    "from pcan_cybergear import CANMotorController"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6b7573f1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-18T06:52:02.224240Z",
     "start_time": "2024-02-18T06:52:02.213912Z"
    }
   },
   "outputs": [],
   "source": [
    "# The CAN ID of the gripper driver is 1\n",
    "gripper = GripperControl(bus, addr=1)\n",
    "\n",
    "# Modify the maximum output voltage in closed-loop mode to adjust the maximum clamping force. The unit is mV, and the maximum value can be 5000mV.\n",
    "gripper.set_max_output_voltage(5000)\n",
    "\n",
    "# Automatically initialize the gripper's open and close positions\n",
    "gripper.init_position()\n",
    "\n",
    "# Close the gripper\n",
    "# gripper.close_gripper()\n",
    "\n",
    "# sleep(3)\n",
    "\n",
    "# Automatically adjust the position to clear any jamming\n",
    "# gripper.clear_clog()\n",
    "\n",
    "# Open the gripper\n",
    "# gripper.open_gripper()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "abb32a37",
   "metadata": {},
   "outputs": [],
   "source": [
    "gripper.set_max_output_voltage(3000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d2035d79",
   "metadata": {},
   "outputs": [],
   "source": [
    "gripper.close_gripper()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "20dfb104",
   "metadata": {},
   "outputs": [],
   "source": [
    "gripper.open_gripper()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1833295",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 480x640 (no detections), 175.6ms\n",
      "Speed: 1.8ms preprocess, 175.6ms inference, 54.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 13.4ms\n",
      "Speed: 2.8ms preprocess, 13.4ms inference, 0.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 16.5ms\n",
      "Speed: 0.0ms preprocess, 16.5ms inference, 2.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 14.8ms\n",
      "Speed: 0.0ms preprocess, 14.8ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 18.9ms\n",
      "Speed: 0.0ms preprocess, 18.9ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 14.8ms\n",
      "Speed: 1.4ms preprocess, 14.8ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 24.1ms\n",
      "Speed: 2.3ms preprocess, 24.1ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 20.5ms\n",
      "Speed: 2.2ms preprocess, 20.5ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 16.2ms\n",
      "Speed: 1.0ms preprocess, 16.2ms inference, 3.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 30.5ms\n",
      "Speed: 0.0ms preprocess, 30.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 34.6ms\n",
      "Speed: 0.0ms preprocess, 34.6ms inference, 5.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 14.4ms\n",
      "Speed: 1.0ms preprocess, 14.4ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 35.0ms\n",
      "Speed: 6.9ms preprocess, 35.0ms inference, 1.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 13.1ms\n",
      "Speed: 0.0ms preprocess, 13.1ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 37.1ms\n",
      "Speed: 3.7ms preprocess, 37.1ms inference, 1.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 18.4ms\n",
      "Speed: 2.3ms preprocess, 18.4ms inference, 0.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 15.6ms\n",
      "Speed: 1.5ms preprocess, 15.6ms inference, 2.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 13.6ms\n",
      "Speed: 0.0ms preprocess, 13.6ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 24.9ms\n",
      "Speed: 2.5ms preprocess, 24.9ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 17.1ms\n",
      "Speed: 0.0ms preprocess, 17.1ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 15.2ms\n",
      "Speed: 1.0ms preprocess, 15.2ms inference, 1.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 26.9ms\n",
      "Speed: 0.0ms preprocess, 26.9ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 15.9ms\n",
      "Speed: 1.0ms preprocess, 15.9ms inference, 2.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 18.7ms\n",
      "Speed: 2.0ms preprocess, 18.7ms inference, 2.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 14.4ms\n",
      "Speed: 0.0ms preprocess, 14.4ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 20.8ms\n",
      "Speed: 0.0ms preprocess, 20.8ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 18.9ms\n",
      "Speed: 1.0ms preprocess, 18.9ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 22.5ms\n",
      "Speed: 1.3ms preprocess, 22.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 10.0ms\n",
      "Speed: 1.0ms preprocess, 10.0ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 12.1ms\n",
      "Speed: 2.0ms preprocess, 12.1ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 21.5ms\n",
      "Speed: 2.3ms preprocess, 21.5ms inference, 2.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 19.3ms\n",
      "Speed: 1.8ms preprocess, 19.3ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 16.7ms\n",
      "Speed: 2.8ms preprocess, 16.7ms inference, 4.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 19.6ms\n",
      "Speed: 0.0ms preprocess, 19.6ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 7.5ms\n",
      "Speed: 1.5ms preprocess, 7.5ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 26.7ms\n",
      "Speed: 6.5ms preprocess, 26.7ms inference, 6.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 12.1ms\n",
      "Speed: 0.0ms preprocess, 12.1ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 17.6ms\n",
      "Speed: 0.0ms preprocess, 17.6ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 17.4ms\n",
      "Speed: 0.0ms preprocess, 17.4ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 29.5ms\n",
      "Speed: 0.0ms preprocess, 29.5ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 16.3ms\n",
      "Speed: 0.0ms preprocess, 16.3ms inference, 5.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 30.3ms\n",
      "Speed: 0.0ms preprocess, 30.3ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 21.8ms\n",
      "Speed: 0.0ms preprocess, 21.8ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 13.3ms\n",
      "Speed: 2.9ms preprocess, 13.3ms inference, 3.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 14.5ms\n",
      "Speed: 0.0ms preprocess, 14.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 17.9ms\n",
      "Speed: 2.2ms preprocess, 17.9ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 21.4ms\n",
      "Speed: 1.3ms preprocess, 21.4ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 32.9ms\n",
      "Speed: 0.0ms preprocess, 32.9ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 25.2ms\n",
      "Speed: 3.0ms preprocess, 25.2ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 15.1ms\n",
      "Speed: 1.0ms preprocess, 15.1ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 18.0ms\n",
      "Speed: 0.0ms preprocess, 18.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 24.6ms\n",
      "Speed: 1.0ms preprocess, 24.6ms inference, 4.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 16.6ms\n",
      "Speed: 0.0ms preprocess, 16.6ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 48.5ms\n",
      "Speed: 3.0ms preprocess, 48.5ms inference, 1.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 16.3ms\n",
      "Speed: 1.6ms preprocess, 16.3ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 9.0ms\n",
      "Speed: 2.0ms preprocess, 9.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 20.8ms\n",
      "Speed: 0.0ms preprocess, 20.8ms inference, 0.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 17.9ms\n",
      "Speed: 0.0ms preprocess, 17.9ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 15.7ms\n",
      "Speed: 0.0ms preprocess, 15.7ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 17.6ms\n",
      "Speed: 1.0ms preprocess, 17.6ms inference, 5.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 14.2ms\n",
      "Speed: 0.0ms preprocess, 14.2ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 20.1ms\n",
      "Speed: 0.0ms preprocess, 20.1ms inference, 2.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 16.5ms\n",
      "Speed: 1.5ms preprocess, 16.5ms inference, 1.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 14.9ms\n",
      "Speed: 0.0ms preprocess, 14.9ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 18.5ms\n",
      "Speed: 1.0ms preprocess, 18.5ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 10.4ms\n",
      "Speed: 2.0ms preprocess, 10.4ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 13.5ms\n",
      "Speed: 1.4ms preprocess, 13.5ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 19.9ms\n",
      "Speed: 2.5ms preprocess, 19.9ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 10.4ms\n",
      "Speed: 2.0ms preprocess, 10.4ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 25.6ms\n",
      "Speed: 3.0ms preprocess, 25.6ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 15.2ms\n",
      "Speed: 1.0ms preprocess, 15.2ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 21.5ms\n",
      "Speed: 2.0ms preprocess, 21.5ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 25.9ms\n",
      "Speed: 4.1ms preprocess, 25.9ms inference, 2.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 18.6ms\n",
      "Speed: 2.3ms preprocess, 18.6ms inference, 0.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 10.2ms\n",
      "Speed: 2.0ms preprocess, 10.2ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 8.4ms\n",
      "Speed: 2.0ms preprocess, 8.4ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 17.6ms\n",
      "Speed: 0.0ms preprocess, 17.6ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 15.5ms\n",
      "Speed: 3.4ms preprocess, 15.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 14.8ms\n",
      "Speed: 2.2ms preprocess, 14.8ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 13.0ms\n",
      "Speed: 1.0ms preprocess, 13.0ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 15.6ms\n",
      "Speed: 1.0ms preprocess, 15.6ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 book, 15.8ms\n",
      "Speed: 2.8ms preprocess, 15.8ms inference, 55.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 book, 13.2ms\n",
      "Speed: 2.8ms preprocess, 13.2ms inference, 1.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 book, 26.4ms\n",
      "Speed: 2.0ms preprocess, 26.4ms inference, 1.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 book, 20.4ms\n",
      "Speed: 4.4ms preprocess, 20.4ms inference, 3.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 book, 16.2ms\n",
      "Speed: 1.5ms preprocess, 16.2ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 book, 16.8ms\n",
      "Speed: 0.6ms preprocess, 16.8ms inference, 6.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 book, 20.1ms\n",
      "Speed: 1.0ms preprocess, 20.1ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 12.9ms\n",
      "Speed: 2.0ms preprocess, 12.9ms inference, 2.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 12.0ms\n",
      "Speed: 4.0ms preprocess, 12.0ms inference, 2.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 12.6ms\n",
      "Speed: 1.4ms preprocess, 12.6ms inference, 2.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 20.8ms\n",
      "Speed: 2.7ms preprocess, 20.8ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 18.0ms\n",
      "Speed: 2.5ms preprocess, 18.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 16.8ms\n",
      "Speed: 2.0ms preprocess, 16.8ms inference, 2.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 15.4ms\n",
      "Speed: 2.0ms preprocess, 15.4ms inference, 1.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 13.7ms\n",
      "Speed: 4.0ms preprocess, 13.7ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 book, 18.0ms\n",
      "Speed: 3.0ms preprocess, 18.0ms inference, 3.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 12.5ms\n",
      "Speed: 3.1ms preprocess, 12.5ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 17.6ms\n",
      "Speed: 3.0ms preprocess, 17.6ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 17.5ms\n",
      "Speed: 3.6ms preprocess, 17.5ms inference, 2.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 remote, 17.6ms\n",
      "Speed: 2.0ms preprocess, 17.6ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 10.0ms\n",
      "Speed: 1.0ms preprocess, 10.0ms inference, 5.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 14.2ms\n",
      "Speed: 1.2ms preprocess, 14.2ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 17.3ms\n",
      "Speed: 1.8ms preprocess, 17.3ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 17.7ms\n",
      "Speed: 4.1ms preprocess, 17.7ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 21.8ms\n",
      "Speed: 2.0ms preprocess, 21.8ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 book, 19.2ms\n",
      "Speed: 3.0ms preprocess, 19.2ms inference, 4.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 16.0ms\n",
      "Speed: 2.1ms preprocess, 16.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 11.1ms\n",
      "Speed: 1.5ms preprocess, 11.1ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 11.1ms\n",
      "Speed: 1.3ms preprocess, 11.1ms inference, 5.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 book, 23.0ms\n",
      "Speed: 2.8ms preprocess, 23.0ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 15.5ms\n",
      "Speed: 0.0ms preprocess, 15.5ms inference, 3.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 19.4ms\n",
      "Speed: 2.1ms preprocess, 19.4ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 13.2ms\n",
      "Speed: 3.0ms preprocess, 13.2ms inference, 1.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 20.8ms\n",
      "Speed: 2.3ms preprocess, 20.8ms inference, 0.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 cell phone, 11.9ms\n",
      "Speed: 0.7ms preprocess, 11.9ms inference, 7.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 20.6ms\n",
      "Speed: 4.5ms preprocess, 20.6ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 12.3ms\n",
      "Speed: 3.0ms preprocess, 12.3ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 cell phone, 20.5ms\n",
      "Speed: 2.7ms preprocess, 20.5ms inference, 4.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 12.2ms\n",
      "Speed: 1.1ms preprocess, 12.2ms inference, 3.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 book, 15.6ms\n",
      "Speed: 0.0ms preprocess, 15.6ms inference, 2.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 book, 10.1ms\n",
      "Speed: 4.0ms preprocess, 10.1ms inference, 1.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 cell phone, 1 book, 10.9ms\n",
      "Speed: 1.0ms preprocess, 10.9ms inference, 4.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 book, 26.8ms\n",
      "Speed: 1.0ms preprocess, 26.8ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 book, 13.0ms\n",
      "Speed: 1.8ms preprocess, 13.0ms inference, 5.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 book, 17.0ms\n",
      "Speed: 3.0ms preprocess, 17.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 book, 19.2ms\n",
      "Speed: 2.0ms preprocess, 19.2ms inference, 3.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 book, 13.8ms\n",
      "Speed: 2.4ms preprocess, 13.8ms inference, 2.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 book, 20.5ms\n",
      "Speed: 0.0ms preprocess, 20.5ms inference, 4.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 book, 21.9ms\n",
      "Speed: 2.7ms preprocess, 21.9ms inference, 3.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 book, 15.0ms\n",
      "Speed: 2.7ms preprocess, 15.0ms inference, 3.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 book, 29.8ms\n",
      "Speed: 0.0ms preprocess, 29.8ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 book, 17.6ms\n",
      "Speed: 3.0ms preprocess, 17.6ms inference, 2.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 16.2ms\n",
      "Speed: 1.9ms preprocess, 16.2ms inference, 2.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 book, 17.6ms\n",
      "Speed: 0.0ms preprocess, 17.6ms inference, 6.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 26.6ms\n",
      "Speed: 3.0ms preprocess, 26.6ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 book, 21.0ms\n",
      "Speed: 4.6ms preprocess, 21.0ms inference, 4.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 book, 20.1ms\n",
      "Speed: 3.0ms preprocess, 20.1ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 19.3ms\n",
      "Speed: 4.0ms preprocess, 19.3ms inference, 1.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 book, 13.6ms\n",
      "Speed: 4.1ms preprocess, 13.6ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 17.5ms\n",
      "Speed: 1.8ms preprocess, 17.5ms inference, 2.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 22.2ms\n",
      "Speed: 2.2ms preprocess, 22.2ms inference, 3.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 13.2ms\n",
      "Speed: 2.2ms preprocess, 13.2ms inference, 2.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 book, 18.4ms\n",
      "Speed: 2.0ms preprocess, 18.4ms inference, 3.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 book, 16.7ms\n",
      "Speed: 0.0ms preprocess, 16.7ms inference, 2.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 book, 20.3ms\n",
      "Speed: 0.0ms preprocess, 20.3ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 book, 13.2ms\n",
      "Speed: 2.3ms preprocess, 13.2ms inference, 4.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 book, 18.2ms\n",
      "Speed: 3.4ms preprocess, 18.2ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 book, 16.2ms\n",
      "Speed: 0.0ms preprocess, 16.2ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 book, 13.0ms\n",
      "Speed: 2.3ms preprocess, 13.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 14.3ms\n",
      "Speed: 2.8ms preprocess, 14.3ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 book, 21.2ms\n",
      "Speed: 0.0ms preprocess, 21.2ms inference, 1.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 16.2ms\n",
      "Speed: 2.4ms preprocess, 16.2ms inference, 2.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 16.1ms\n",
      "Speed: 0.0ms preprocess, 16.1ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 13.3ms\n",
      "Speed: 2.9ms preprocess, 13.3ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 16.3ms\n",
      "Speed: 1.0ms preprocess, 16.3ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 18.5ms\n",
      "Speed: 2.6ms preprocess, 18.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 15.5ms\n",
      "Speed: 3.0ms preprocess, 15.5ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 18.2ms\n",
      "Speed: 2.0ms preprocess, 18.2ms inference, 2.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 16.1ms\n",
      "Speed: 3.4ms preprocess, 16.1ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 16.7ms\n",
      "Speed: 0.0ms preprocess, 16.7ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 11.1ms\n",
      "Speed: 1.6ms preprocess, 11.1ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 19.1ms\n",
      "Speed: 1.5ms preprocess, 19.1ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 18.2ms\n",
      "Speed: 3.1ms preprocess, 18.2ms inference, 0.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 13.5ms\n",
      "Speed: 1.8ms preprocess, 13.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 10.4ms\n",
      "Speed: 1.0ms preprocess, 10.4ms inference, 6.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 15.6ms\n",
      "Speed: 3.0ms preprocess, 15.6ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 15.1ms\n",
      "Speed: 2.0ms preprocess, 15.1ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 16.0ms\n",
      "Speed: 1.0ms preprocess, 16.0ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from ultralytics import YOLO\n",
    "from cv2 import getTickCount, getTickFrequency\n",
    "import ollama\n",
    "import re\n",
    "import time\n",
    "import json  # Import the json module\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "from collections import defaultdict\n",
    "\n",
    "# Load the YOLOv11 model\n",
    "model = YOLO(\"weights/yolo11s.pt\")\n",
    "\n",
    "# Capture video from the camera\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "# Global variables\n",
    "force_cache = {}  # Cache for force values\n",
    "last_query_time = {}  # Record the last query time for each object\n",
    "QUERY_INTERVAL = 5  # Query interval for each object (seconds)\n",
    "current_force = None  # Current force value in use\n",
    "executor = ThreadPoolExecutor(max_workers=1)  # For asynchronous force value queries\n",
    "\n",
    "# Define the list of interested class IDs\n",
    "INTERESTED_CLASSES = {\n",
    "    39: 'bottle',     # LayerD\n",
    "    41: 'cup',        # LayerD\n",
    "    44: 'spoon',      # LayerD\n",
    "    47: 'apple',      # LayerC\n",
    "    49: 'orange',     # LayerB\n",
    "    50: 'broccoli',   # LayerC\n",
    "    51: 'carrot',     # LayerC\n",
    "    65: 'remote',     # LayerD\n",
    "    67: 'cell phone', # LayerD\n",
    "    73: 'book',       # LayerD\n",
    "    76: 'scissors',   # LayerD\n",
    "    79: 'toothbrush', # LayerD\n",
    "}\n",
    "\n",
    "def get_force_value(object_name):\n",
    "    message_content = f\"\"\"\n",
    "    Based on the following dictionaries, determine which level the object '[object_name]' is most similar to, and output only the corresponding value of that level as a single number. If the object is not listed, use your best judgment to determine the closest match and output the value for that level. Do not include any code or text, only a number.\n",
    "\n",
    "    Dictionary of hierarchical structures and corresponding object arrays:\n",
    "\n",
    "    \"LayerA\": [\"cup\"],  # Soft Texture Items\n",
    "    \"LayerB\": [\"orange\"],  # Moderately Soft Texture Items\n",
    "    \"LayerC\": [\"broccoli\", \"carrot\", \"apple\"],  # Hard Texture Items\n",
    "    \"LayerD\": [\"bottle\", \"remote\", \"cell phone\", \"book\"],  # Hard items\n",
    "    \"LayerE\": [\"spoon\", \"scissors\", \"toothbrush\"]  # Very Hard Items\n",
    "\n",
    "    Dictionary of hierarchical structures and corresponding values:\n",
    "\n",
    "        'LayerA': 1000,\n",
    "        'LayerB': 2000,\n",
    "        'LayerC': 3000,\n",
    "        'LayerD': 4000,\n",
    "        'LayerE': 5000\n",
    "\n",
    "\n",
    "    Based on the typical weight characteristics of '{object_name}', determine which level it belongs to and output only the corresponding value.\n",
    "    \"\"\"\n",
    "\n",
    "    try:\n",
    "        response = ollama.chat(model=\"llama3.2\", stream=False, messages=[{\n",
    "            \"role\": \"assistant\",\n",
    "            \"content\": message_content\n",
    "        }], options={\"temperature\": 0.5})\n",
    "        content = response['message']['content']\n",
    "        numbers = re.findall(r'\\d+', content)\n",
    "        return int(numbers[0]) if numbers else 5000\n",
    "    except Exception as e:\n",
    "        print(f\"Force value query error: {e}\")\n",
    "        return 5000  # Return default value when error occurs\n",
    "\n",
    "def update_force_value(object_name):\n",
    "    \"\"\"Wrapper function for asynchronous force value updates\"\"\"\n",
    "    force_value = get_force_value(object_name)\n",
    "    force_cache[object_name] = force_value\n",
    "    last_query_time[object_name] = time.time()\n",
    "    return force_value\n",
    "\n",
    "def get_current_force(detected_objects):\n",
    "    \"\"\"Get the current force value to be used\"\"\"\n",
    "    global current_force\n",
    "    \n",
    "    if not detected_objects:\n",
    "        current_force = None\n",
    "        return None\n",
    "\n",
    "    current_time = time.time()\n",
    "    for obj_name in detected_objects:\n",
    "        # If the object is not in the cache\n",
    "        if obj_name not in force_cache:\n",
    "            # Synchronously update the force value (only on the first detection)\n",
    "            force_value = get_force_value(object_name)\n",
    "            force_cache[obj_name] = force_value\n",
    "            last_query_time[obj_name] = time.time()\n",
    "        # If the object is in the cache but the query interval has passed\n",
    "        elif current_time - last_query_time.get(obj_name, 0) > QUERY_INTERVAL:\n",
    "            # Asynchronously update the force value\n",
    "            executor.submit(update_force_value, obj_name)    \n",
    "    # Use the maximum force value from the cache\n",
    "    max_force = max([force_cache.get(obj, 5000) for obj in detected_objects])\n",
    "    current_force = max_force\n",
    "    return current_force\n",
    "\n",
    "def write_to_file(detected_objects, force):\n",
    "    \"\"\"Append detected object names and force to a text file in JSON array format\"\"\"\n",
    "    # Read existing data from the file (if it exists)\n",
    "    try:\n",
    "        with open(\"detected_objects.json\", \"r\") as file:\n",
    "            data = json.load(file)  # Load existing JSON data\n",
    "    except (FileNotFoundError, json.JSONDecodeError):\n",
    "        # Initialize an empty list if the file does not exist or contains invalid JSON\n",
    "        data = []\n",
    "    \n",
    "    # Append new detection results to the data\n",
    "    for obj in detected_objects:\n",
    "        data.append({\"object\": obj, \"force\": force})  # Store each object and force as a dictionary\n",
    "    \n",
    "    # Write the updated data back to the file in JSON format\n",
    "    with open(\"detected_objects.json\", \"w\") as file:\n",
    "        json.dump(data, file, indent=4)  # Use indent=4 for readability\n",
    "\n",
    "# Record the start time of the program\n",
    "start_time = time.time()\n",
    "\n",
    "while cap.isOpened():\n",
    "    loop_start = getTickCount()\n",
    "    success, frame = cap.read()\n",
    "    \n",
    "    if success:\n",
    "        # Add class filtering\n",
    "        results = model.predict(source=frame, classes=list(INTERESTED_CLASSES.keys()))\n",
    "        result = results[0]\n",
    "        boxes = result.boxes\n",
    "        \n",
    "        # Get all detected objects in the current frame (only interested classes)\n",
    "        detected_objects = []\n",
    "        for cls_id in boxes.cls:\n",
    "            cls_id = int(cls_id)\n",
    "            if cls_id in INTERESTED_CLASSES:\n",
    "                detected_objects.append(INTERESTED_CLASSES[cls_id])\n",
    "        \n",
    "        # Update force value\n",
    "        force = get_current_force(detected_objects)\n",
    "        \n",
    "        # Write detected object names and force to a text file in JSON format\n",
    "        if detected_objects and force:\n",
    "            write_to_file(detected_objects, force)\n",
    "        \n",
    "        # Display detected objects and force value on the frame\n",
    "        annotated_frame = results[0].plot()\n",
    "        \n",
    "        # Calculate FPS\n",
    "        loop_time = getTickCount() - loop_start\n",
    "        fps = int(getTickFrequency() / loop_time)\n",
    "        \n",
    "        # Display information\n",
    "        font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "        cv2.putText(annotated_frame, f\"FPS: {fps}\", (10, 30), font, 1, (0, 0, 255), 2)\n",
    "        if force:\n",
    "            cv2.putText(annotated_frame, f\"Force: {force}\", (10, 70), font, 1, (0, 255, 0), 2)\n",
    "        \n",
    "        # Display detected object names\n",
    "        y_offset = 110\n",
    "        for obj in detected_objects:\n",
    "            cv2.putText(annotated_frame, f\"Detected: {obj}\", (10, y_offset), font, 0.7, (255, 0, 0), 2)\n",
    "            y_offset += 30\n",
    "        \n",
    "        cv2.imshow('Object Detection', annotated_frame)\n",
    "    \n",
    "    # Check if more than 20 seconds have passed\n",
    "    # if time.time() - start_time > 20:\n",
    "    #     break\n",
    "\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "executor.shutdown(wait=False)\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "26aa7373",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Latest force value: 4000\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "def print_latest_force():\n",
    "    \"\"\"Print the force value from the latest entry in the detected_objects.json file.\"\"\"\n",
    "    try:\n",
    "        # Read the JSON file\n",
    "        with open(\"detected_objects.json\", \"r\") as file:\n",
    "            data = json.load(file)  # Load JSON data\n",
    "        \n",
    "        # Check if the data is empty\n",
    "        if not data:\n",
    "            print(\"No data found in detected_objects.json.\")\n",
    "            return\n",
    "        \n",
    "        # Get the latest entry\n",
    "        latest_entry = data[-1]  # The last element in the list is the latest entry\n",
    "        \n",
    "        # Extract the force value\n",
    "        force = latest_entry.get(\"force\")\n",
    "        \n",
    "        # Print the force value\n",
    "        if force is not None:\n",
    "            print(f\"Latest force value: {force}\")\n",
    "        else:\n",
    "            print(\"No force value found in the latest entry.\")\n",
    "    \n",
    "    except FileNotFoundError:\n",
    "        print(\"File detected_objects.json not found.\")\n",
    "    except json.JSONDecodeError:\n",
    "        print(\"Invalid JSON format in detected_objects.json.\")\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "\n",
    "# Call the function to print the latest force value\n",
    "print_latest_force()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8f4ca7df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "print(force)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
