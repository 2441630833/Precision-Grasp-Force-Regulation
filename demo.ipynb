{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "24b767a4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-18T06:51:54.135290Z",
     "start_time": "2024-02-18T06:51:54.130292Z"
    }
   },
   "outputs": [],
   "source": [
    "import logging\n",
    "import can\n",
    "from time import sleep\n",
    "\n",
    "# Initialize logging\n",
    "logging.basicConfig(\n",
    "    level=logging.ERROR, format=\"%(asctime)s - %(levelname)s - %(message)s\"\n",
    ")\n",
    "\n",
    "# 初始化CAN总线\n",
    "bus = can.interface.Bus(interface=\"pcan\", channel=\"PCAN_USBBUS1\", bitrate=1000000)\n",
    "########################################\n",
    "# 导入机械爪和小米微电机CAN总线库\n",
    "########################################\n",
    "from gripper_control import GripperControl\n",
    "from pcan_cybergear import CANMotorController"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6b7573f1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-18T06:52:02.224240Z",
     "start_time": "2024-02-18T06:52:02.213912Z"
    }
   },
   "outputs": [],
   "source": [
    "# 机械爪驱动器CAN ID为1\n",
    "gripper = GripperControl(bus, addr=1)\n",
    "\n",
    "# 修改闭环模式最大输出电压，从而调整最大输出加持力量，单位mV，最大可以是 5000mV\n",
    "gripper.set_max_output_voltage(5000)\n",
    "\n",
    "# 自动初始化爪开合位置\n",
    "gripper.init_position()\n",
    "\n",
    "# 合\n",
    "# gripper.close_gripper()\n",
    "\n",
    "# sleep(3)\n",
    "\n",
    "# 自动调整位置以解除卡顿\n",
    "# gripper.clear_clog()\n",
    "\n",
    "# 开\n",
    "# gripper.open_gripper()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "abb32a37",
   "metadata": {},
   "outputs": [],
   "source": [
    "gripper.set_max_output_voltage(3000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d2035d79",
   "metadata": {},
   "outputs": [],
   "source": [
    "gripper.close_gripper()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "20dfb104",
   "metadata": {},
   "outputs": [],
   "source": [
    "gripper.open_gripper()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1833295",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 480x640 (no detections), 175.6ms\n",
      "Speed: 1.8ms preprocess, 175.6ms inference, 54.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 13.4ms\n",
      "Speed: 2.8ms preprocess, 13.4ms inference, 0.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 16.5ms\n",
      "Speed: 0.0ms preprocess, 16.5ms inference, 2.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 14.8ms\n",
      "Speed: 0.0ms preprocess, 14.8ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 18.9ms\n",
      "Speed: 0.0ms preprocess, 18.9ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 14.8ms\n",
      "Speed: 1.4ms preprocess, 14.8ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 24.1ms\n",
      "Speed: 2.3ms preprocess, 24.1ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 20.5ms\n",
      "Speed: 2.2ms preprocess, 20.5ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 16.2ms\n",
      "Speed: 1.0ms preprocess, 16.2ms inference, 3.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 30.5ms\n",
      "Speed: 0.0ms preprocess, 30.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 34.6ms\n",
      "Speed: 0.0ms preprocess, 34.6ms inference, 5.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 14.4ms\n",
      "Speed: 1.0ms preprocess, 14.4ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 35.0ms\n",
      "Speed: 6.9ms preprocess, 35.0ms inference, 1.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 13.1ms\n",
      "Speed: 0.0ms preprocess, 13.1ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 37.1ms\n",
      "Speed: 3.7ms preprocess, 37.1ms inference, 1.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 18.4ms\n",
      "Speed: 2.3ms preprocess, 18.4ms inference, 0.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 15.6ms\n",
      "Speed: 1.5ms preprocess, 15.6ms inference, 2.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 13.6ms\n",
      "Speed: 0.0ms preprocess, 13.6ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 24.9ms\n",
      "Speed: 2.5ms preprocess, 24.9ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 17.1ms\n",
      "Speed: 0.0ms preprocess, 17.1ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 15.2ms\n",
      "Speed: 1.0ms preprocess, 15.2ms inference, 1.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 26.9ms\n",
      "Speed: 0.0ms preprocess, 26.9ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 15.9ms\n",
      "Speed: 1.0ms preprocess, 15.9ms inference, 2.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 18.7ms\n",
      "Speed: 2.0ms preprocess, 18.7ms inference, 2.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 14.4ms\n",
      "Speed: 0.0ms preprocess, 14.4ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 20.8ms\n",
      "Speed: 0.0ms preprocess, 20.8ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 18.9ms\n",
      "Speed: 1.0ms preprocess, 18.9ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 22.5ms\n",
      "Speed: 1.3ms preprocess, 22.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 10.0ms\n",
      "Speed: 1.0ms preprocess, 10.0ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 12.1ms\n",
      "Speed: 2.0ms preprocess, 12.1ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 21.5ms\n",
      "Speed: 2.3ms preprocess, 21.5ms inference, 2.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 19.3ms\n",
      "Speed: 1.8ms preprocess, 19.3ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 16.7ms\n",
      "Speed: 2.8ms preprocess, 16.7ms inference, 4.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 19.6ms\n",
      "Speed: 0.0ms preprocess, 19.6ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 7.5ms\n",
      "Speed: 1.5ms preprocess, 7.5ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 26.7ms\n",
      "Speed: 6.5ms preprocess, 26.7ms inference, 6.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 12.1ms\n",
      "Speed: 0.0ms preprocess, 12.1ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 17.6ms\n",
      "Speed: 0.0ms preprocess, 17.6ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 17.4ms\n",
      "Speed: 0.0ms preprocess, 17.4ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 29.5ms\n",
      "Speed: 0.0ms preprocess, 29.5ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 16.3ms\n",
      "Speed: 0.0ms preprocess, 16.3ms inference, 5.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 30.3ms\n",
      "Speed: 0.0ms preprocess, 30.3ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 21.8ms\n",
      "Speed: 0.0ms preprocess, 21.8ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 13.3ms\n",
      "Speed: 2.9ms preprocess, 13.3ms inference, 3.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 14.5ms\n",
      "Speed: 0.0ms preprocess, 14.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 17.9ms\n",
      "Speed: 2.2ms preprocess, 17.9ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 21.4ms\n",
      "Speed: 1.3ms preprocess, 21.4ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 32.9ms\n",
      "Speed: 0.0ms preprocess, 32.9ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 25.2ms\n",
      "Speed: 3.0ms preprocess, 25.2ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 15.1ms\n",
      "Speed: 1.0ms preprocess, 15.1ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 18.0ms\n",
      "Speed: 0.0ms preprocess, 18.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 24.6ms\n",
      "Speed: 1.0ms preprocess, 24.6ms inference, 4.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 16.6ms\n",
      "Speed: 0.0ms preprocess, 16.6ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 48.5ms\n",
      "Speed: 3.0ms preprocess, 48.5ms inference, 1.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 16.3ms\n",
      "Speed: 1.6ms preprocess, 16.3ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 9.0ms\n",
      "Speed: 2.0ms preprocess, 9.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 20.8ms\n",
      "Speed: 0.0ms preprocess, 20.8ms inference, 0.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 17.9ms\n",
      "Speed: 0.0ms preprocess, 17.9ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 15.7ms\n",
      "Speed: 0.0ms preprocess, 15.7ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 17.6ms\n",
      "Speed: 1.0ms preprocess, 17.6ms inference, 5.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 14.2ms\n",
      "Speed: 0.0ms preprocess, 14.2ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 20.1ms\n",
      "Speed: 0.0ms preprocess, 20.1ms inference, 2.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 16.5ms\n",
      "Speed: 1.5ms preprocess, 16.5ms inference, 1.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 14.9ms\n",
      "Speed: 0.0ms preprocess, 14.9ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 18.5ms\n",
      "Speed: 1.0ms preprocess, 18.5ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 10.4ms\n",
      "Speed: 2.0ms preprocess, 10.4ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 13.5ms\n",
      "Speed: 1.4ms preprocess, 13.5ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 19.9ms\n",
      "Speed: 2.5ms preprocess, 19.9ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 10.4ms\n",
      "Speed: 2.0ms preprocess, 10.4ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 25.6ms\n",
      "Speed: 3.0ms preprocess, 25.6ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 15.2ms\n",
      "Speed: 1.0ms preprocess, 15.2ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 21.5ms\n",
      "Speed: 2.0ms preprocess, 21.5ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 25.9ms\n",
      "Speed: 4.1ms preprocess, 25.9ms inference, 2.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 18.6ms\n",
      "Speed: 2.3ms preprocess, 18.6ms inference, 0.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 10.2ms\n",
      "Speed: 2.0ms preprocess, 10.2ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 8.4ms\n",
      "Speed: 2.0ms preprocess, 8.4ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 17.6ms\n",
      "Speed: 0.0ms preprocess, 17.6ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 15.5ms\n",
      "Speed: 3.4ms preprocess, 15.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 14.8ms\n",
      "Speed: 2.2ms preprocess, 14.8ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 13.0ms\n",
      "Speed: 1.0ms preprocess, 13.0ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 15.6ms\n",
      "Speed: 1.0ms preprocess, 15.6ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 book, 15.8ms\n",
      "Speed: 2.8ms preprocess, 15.8ms inference, 55.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 book, 13.2ms\n",
      "Speed: 2.8ms preprocess, 13.2ms inference, 1.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 book, 26.4ms\n",
      "Speed: 2.0ms preprocess, 26.4ms inference, 1.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 book, 20.4ms\n",
      "Speed: 4.4ms preprocess, 20.4ms inference, 3.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 book, 16.2ms\n",
      "Speed: 1.5ms preprocess, 16.2ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 book, 16.8ms\n",
      "Speed: 0.6ms preprocess, 16.8ms inference, 6.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 book, 20.1ms\n",
      "Speed: 1.0ms preprocess, 20.1ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 12.9ms\n",
      "Speed: 2.0ms preprocess, 12.9ms inference, 2.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 12.0ms\n",
      "Speed: 4.0ms preprocess, 12.0ms inference, 2.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 12.6ms\n",
      "Speed: 1.4ms preprocess, 12.6ms inference, 2.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 20.8ms\n",
      "Speed: 2.7ms preprocess, 20.8ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 18.0ms\n",
      "Speed: 2.5ms preprocess, 18.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 16.8ms\n",
      "Speed: 2.0ms preprocess, 16.8ms inference, 2.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 15.4ms\n",
      "Speed: 2.0ms preprocess, 15.4ms inference, 1.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 13.7ms\n",
      "Speed: 4.0ms preprocess, 13.7ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 book, 18.0ms\n",
      "Speed: 3.0ms preprocess, 18.0ms inference, 3.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 12.5ms\n",
      "Speed: 3.1ms preprocess, 12.5ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 17.6ms\n",
      "Speed: 3.0ms preprocess, 17.6ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 17.5ms\n",
      "Speed: 3.6ms preprocess, 17.5ms inference, 2.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 remote, 17.6ms\n",
      "Speed: 2.0ms preprocess, 17.6ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 10.0ms\n",
      "Speed: 1.0ms preprocess, 10.0ms inference, 5.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 14.2ms\n",
      "Speed: 1.2ms preprocess, 14.2ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 17.3ms\n",
      "Speed: 1.8ms preprocess, 17.3ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 17.7ms\n",
      "Speed: 4.1ms preprocess, 17.7ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 21.8ms\n",
      "Speed: 2.0ms preprocess, 21.8ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 book, 19.2ms\n",
      "Speed: 3.0ms preprocess, 19.2ms inference, 4.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 16.0ms\n",
      "Speed: 2.1ms preprocess, 16.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 11.1ms\n",
      "Speed: 1.5ms preprocess, 11.1ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 11.1ms\n",
      "Speed: 1.3ms preprocess, 11.1ms inference, 5.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 book, 23.0ms\n",
      "Speed: 2.8ms preprocess, 23.0ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 15.5ms\n",
      "Speed: 0.0ms preprocess, 15.5ms inference, 3.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 19.4ms\n",
      "Speed: 2.1ms preprocess, 19.4ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 13.2ms\n",
      "Speed: 3.0ms preprocess, 13.2ms inference, 1.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 20.8ms\n",
      "Speed: 2.3ms preprocess, 20.8ms inference, 0.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 cell phone, 11.9ms\n",
      "Speed: 0.7ms preprocess, 11.9ms inference, 7.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 20.6ms\n",
      "Speed: 4.5ms preprocess, 20.6ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 12.3ms\n",
      "Speed: 3.0ms preprocess, 12.3ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 cell phone, 20.5ms\n",
      "Speed: 2.7ms preprocess, 20.5ms inference, 4.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 12.2ms\n",
      "Speed: 1.1ms preprocess, 12.2ms inference, 3.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 book, 15.6ms\n",
      "Speed: 0.0ms preprocess, 15.6ms inference, 2.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 book, 10.1ms\n",
      "Speed: 4.0ms preprocess, 10.1ms inference, 1.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 cell phone, 1 book, 10.9ms\n",
      "Speed: 1.0ms preprocess, 10.9ms inference, 4.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 book, 26.8ms\n",
      "Speed: 1.0ms preprocess, 26.8ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 book, 13.0ms\n",
      "Speed: 1.8ms preprocess, 13.0ms inference, 5.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 book, 17.0ms\n",
      "Speed: 3.0ms preprocess, 17.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 book, 19.2ms\n",
      "Speed: 2.0ms preprocess, 19.2ms inference, 3.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 book, 13.8ms\n",
      "Speed: 2.4ms preprocess, 13.8ms inference, 2.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 book, 20.5ms\n",
      "Speed: 0.0ms preprocess, 20.5ms inference, 4.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 book, 21.9ms\n",
      "Speed: 2.7ms preprocess, 21.9ms inference, 3.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 book, 15.0ms\n",
      "Speed: 2.7ms preprocess, 15.0ms inference, 3.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 book, 29.8ms\n",
      "Speed: 0.0ms preprocess, 29.8ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 book, 17.6ms\n",
      "Speed: 3.0ms preprocess, 17.6ms inference, 2.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 16.2ms\n",
      "Speed: 1.9ms preprocess, 16.2ms inference, 2.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 book, 17.6ms\n",
      "Speed: 0.0ms preprocess, 17.6ms inference, 6.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 26.6ms\n",
      "Speed: 3.0ms preprocess, 26.6ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 book, 21.0ms\n",
      "Speed: 4.6ms preprocess, 21.0ms inference, 4.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 book, 20.1ms\n",
      "Speed: 3.0ms preprocess, 20.1ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 19.3ms\n",
      "Speed: 4.0ms preprocess, 19.3ms inference, 1.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 book, 13.6ms\n",
      "Speed: 4.1ms preprocess, 13.6ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 17.5ms\n",
      "Speed: 1.8ms preprocess, 17.5ms inference, 2.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 22.2ms\n",
      "Speed: 2.2ms preprocess, 22.2ms inference, 3.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 13.2ms\n",
      "Speed: 2.2ms preprocess, 13.2ms inference, 2.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 book, 18.4ms\n",
      "Speed: 2.0ms preprocess, 18.4ms inference, 3.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 book, 16.7ms\n",
      "Speed: 0.0ms preprocess, 16.7ms inference, 2.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 book, 20.3ms\n",
      "Speed: 0.0ms preprocess, 20.3ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 book, 13.2ms\n",
      "Speed: 2.3ms preprocess, 13.2ms inference, 4.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 book, 18.2ms\n",
      "Speed: 3.4ms preprocess, 18.2ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 book, 16.2ms\n",
      "Speed: 0.0ms preprocess, 16.2ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 book, 13.0ms\n",
      "Speed: 2.3ms preprocess, 13.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 14.3ms\n",
      "Speed: 2.8ms preprocess, 14.3ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 book, 21.2ms\n",
      "Speed: 0.0ms preprocess, 21.2ms inference, 1.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 16.2ms\n",
      "Speed: 2.4ms preprocess, 16.2ms inference, 2.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 16.1ms\n",
      "Speed: 0.0ms preprocess, 16.1ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 13.3ms\n",
      "Speed: 2.9ms preprocess, 13.3ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 16.3ms\n",
      "Speed: 1.0ms preprocess, 16.3ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 18.5ms\n",
      "Speed: 2.6ms preprocess, 18.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 15.5ms\n",
      "Speed: 3.0ms preprocess, 15.5ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 18.2ms\n",
      "Speed: 2.0ms preprocess, 18.2ms inference, 2.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 16.1ms\n",
      "Speed: 3.4ms preprocess, 16.1ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 16.7ms\n",
      "Speed: 0.0ms preprocess, 16.7ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 11.1ms\n",
      "Speed: 1.6ms preprocess, 11.1ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 19.1ms\n",
      "Speed: 1.5ms preprocess, 19.1ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 18.2ms\n",
      "Speed: 3.1ms preprocess, 18.2ms inference, 0.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 13.5ms\n",
      "Speed: 1.8ms preprocess, 13.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 10.4ms\n",
      "Speed: 1.0ms preprocess, 10.4ms inference, 6.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 15.6ms\n",
      "Speed: 3.0ms preprocess, 15.6ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 15.1ms\n",
      "Speed: 2.0ms preprocess, 15.1ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 16.0ms\n",
      "Speed: 1.0ms preprocess, 16.0ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from ultralytics import YOLO\n",
    "from cv2 import getTickCount, getTickFrequency\n",
    "import ollama\n",
    "import re\n",
    "import time\n",
    "import json  # 导入 json 模块\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "from collections import defaultdict\n",
    "# 加载 YOLOv11 模型\n",
    "model = YOLO(\"weights/yolo11s.pt\")\n",
    "\n",
    "# 获取摄像头内容\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "# 全局变量\n",
    "force_cache = {}  # 缓存力度值\n",
    "last_query_time = {}  # 记录每个物体最后查询时间\n",
    "QUERY_INTERVAL = 5  # 每个物体的查询间隔（秒）\n",
    "current_force = None  # 当前使用的力度值\n",
    "executor = ThreadPoolExecutor(max_workers=1)  # 用于异步执行力度查询\n",
    "\n",
    "# 定义我们感兴趣的类别ID列表\n",
    "INTERESTED_CLASSES = {\n",
    "    39: 'bottle',     # LayerD\n",
    "    41: 'cup',        # LayerD\n",
    "    44: 'spoon',      # LayerD\n",
    "    47: 'apple',      # LayerC\n",
    "    49: 'orange',     # LayerB\n",
    "    50: 'broccoli',   # LayerC\n",
    "    51: 'carrot',     # LayerC\n",
    "    65: 'remote',     # LayerD\n",
    "    67: 'cell phone', # LayerD\n",
    "    73: 'book',       # LayerD\n",
    "    76: 'scissors',   # LayerD\n",
    "    79: 'toothbrush', # LayerD\n",
    "}\n",
    "\n",
    "def get_force_value(object_name):\n",
    "    message_content = f\"\"\"\n",
    "    Based on the following dictionaries, determine which level the object '[object_name]' is most similar to, and output only the corresponding value of that level as a single number. If the object is not listed, use your best judgment to determine the closest match and output the value for that level. Do not include any code or text, only a number.\n",
    "\n",
    "    Dictionary of hierarchical structures and corresponding object arrays:\n",
    "\n",
    "    \"LayerA\": [\"cup\"],  # Soft Texture Items\n",
    "    \"LayerB\": [\"orange\"],  # Moderately Soft Texture Items\n",
    "    \"LayerC\": [\"broccoli\", \"carrot\", \"apple\"],  # Hard Texture Items\n",
    "    \"LayerD\": [\"bottle\", \"remote\", \"cell phone\", \"book\"],  # Hard items\n",
    "    \"LayerE\": [\"spoon\", \"scissors\", \"toothbrush\"]  # Very Hard Items\n",
    "\n",
    "    Dictionary of hierarchical structures and corresponding values:\n",
    "\n",
    "        'LayerA': 1000,\n",
    "        'LayerB': 2000,\n",
    "        'LayerC': 3000,\n",
    "        'LayerD': 4000,\n",
    "        'LayerE': 5000\n",
    "\n",
    "\n",
    "    Based on the typical weight characteristics of '{object_name}', determine which level it belongs to and output only the corresponding value.\n",
    "    \"\"\"\n",
    "\n",
    "    try:\n",
    "        response = ollama.chat(model=\"llama3.2\", stream=False, messages=[{\n",
    "            \"role\": \"assistant\",\n",
    "            \"content\": message_content\n",
    "        }], options={\"temperature\": 0.5})\n",
    "        content = response['message']['content']\n",
    "        numbers = re.findall(r'\\d+', content)\n",
    "        return int(numbers[0]) if numbers else 5000\n",
    "    except Exception as e:\n",
    "        print(f\"Force value query error: {e}\")\n",
    "        return 5000  # Return default value when error occurs\n",
    "\n",
    "def update_force_value(object_name):\n",
    "    \"\"\"异步更新力度值的包装函数\"\"\"\n",
    "    force_value = get_force_value(object_name)\n",
    "    force_cache[object_name] = force_value\n",
    "    last_query_time[object_name] = time.time()\n",
    "    return force_value\n",
    "\n",
    "def get_current_force(detected_objects):\n",
    "    \"\"\"获取当前应该使用的力度值\"\"\"\n",
    "    global current_force\n",
    "    \n",
    "    if not detected_objects:\n",
    "        current_force = None\n",
    "        return None\n",
    "\n",
    "    current_time = time.time()\n",
    "    for obj_name in detected_objects:\n",
    "        # 如果物体不在缓存中\n",
    "        if obj_name not in force_cache:\n",
    "            # 同步更新力度值（仅在第一次检测到物体时）\n",
    "            force_value = get_force_value(obj_name)\n",
    "            force_cache[obj_name] = force_value\n",
    "            last_query_time[obj_name] = time.time()\n",
    "        # 如果物体在缓存中但超过查询间隔\n",
    "        elif current_time - last_query_time.get(obj_name, 0) > QUERY_INTERVAL:\n",
    "            # 异步更新力度值\n",
    "            executor.submit(update_force_value, obj_name)    \n",
    "    # # # 遍历检测到的物体，更新力度值\n",
    "    # for obj_name in detected_objects:\n",
    "    #     # 如果物体不在缓存中，或者超过查询间隔\n",
    "    #     if obj_name not in force_cache or current_time - last_query_time.get(obj_name, 0) > QUERY_INTERVAL:\n",
    "    #         # 异步更新力度值\n",
    "    #         executor.submit(update_force_value, obj_name)\n",
    "    \n",
    "    # 使用缓存中的最大力度值\n",
    "    max_force = max([force_cache.get(obj, 5000) for obj in detected_objects])\n",
    "    current_force = max_force\n",
    "    return current_force\n",
    "\n",
    "def write_to_file(detected_objects, force):\n",
    "    \"\"\"将检测到的物体名称和force以JSON数组格式追加写入文本文件\"\"\"\n",
    "    # 读取文件中已有的数据（如果文件存在）\n",
    "    try:\n",
    "        with open(\"detected_objects.json\", \"r\") as file:\n",
    "            data = json.load(file)  # 读取已有的JSON数据\n",
    "    except (FileNotFoundError, json.JSONDecodeError):\n",
    "        # 如果文件不存在或文件内容不是有效的JSON，初始化一个空列表\n",
    "        data = []\n",
    "    \n",
    "    # 将新的检测结果追加到数据中\n",
    "    for obj in detected_objects:\n",
    "        data.append({\"object\": obj, \"force\": force})  # 将每个物体和force存储为字典\n",
    "    \n",
    "    # 将更新后的数据以JSON格式写回文件\n",
    "    with open(\"detected_objects.json\", \"w\") as file:\n",
    "        json.dump(data, file, indent=4)  # 使用indent=4使文件更易读\n",
    "\n",
    "# 记录程序开始时间\n",
    "start_time = time.time()\n",
    "\n",
    "while cap.isOpened():\n",
    "    loop_start = getTickCount()\n",
    "    success, frame = cap.read()\n",
    "    \n",
    "    if success:\n",
    "        # 添加类别过滤\n",
    "        results = model.predict(source=frame, classes=list(INTERESTED_CLASSES.keys()))\n",
    "        result = results[0]\n",
    "        boxes = result.boxes\n",
    "        \n",
    "        # 获取当前帧检测到的所有物体（只包含感兴趣的类别）\n",
    "        detected_objects = []\n",
    "        for cls_id in boxes.cls:\n",
    "            cls_id = int(cls_id)\n",
    "            if cls_id in INTERESTED_CLASSES:\n",
    "                detected_objects.append(INTERESTED_CLASSES[cls_id])\n",
    "        \n",
    "        # 更新力度值\n",
    "        force = get_current_force(detected_objects)\n",
    "        \n",
    "        # 将检测到的物体名称和force以JSON格式写入文本文件\n",
    "        if detected_objects and force:\n",
    "            write_to_file(detected_objects, force)\n",
    "        \n",
    "        # 在画面上显示检测到的物体和力度值\n",
    "        annotated_frame = results[0].plot()\n",
    "        \n",
    "        # 计算FPS\n",
    "        loop_time = getTickCount() - loop_start\n",
    "        fps = int(getTickFrequency() / loop_time)\n",
    "        \n",
    "        # 显示信息\n",
    "        font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "        cv2.putText(annotated_frame, f\"FPS: {fps}\", (10, 30), font, 1, (0, 0, 255), 2)\n",
    "        if force:\n",
    "            cv2.putText(annotated_frame, f\"Force: {force}\", (10, 70), font, 1, (0, 255, 0), 2)\n",
    "        \n",
    "        # 显示检测到的物体名称\n",
    "        y_offset = 110\n",
    "        for obj in detected_objects:\n",
    "            cv2.putText(annotated_frame, f\"Detected: {obj}\", (10, y_offset), font, 0.7, (255, 0, 0), 2)\n",
    "            y_offset += 30\n",
    "        \n",
    "        cv2.imshow('Object Detection', annotated_frame)\n",
    "    \n",
    "    # 检查是否超过20秒\n",
    "    # if time.time() - start_time > 20:\n",
    "    #     break\n",
    "\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "executor.shutdown(wait=False)\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "26aa7373",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Latest force value: 4000\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "def print_latest_force():\n",
    "    \"\"\"打印 detected_objects.json 文件中最新一条记录的 force 值\"\"\"\n",
    "    try:\n",
    "        # 读取 JSON 文件\n",
    "        with open(\"detected_objects.json\", \"r\") as file:\n",
    "            data = json.load(file)  # 读取 JSON 数据\n",
    "        \n",
    "        # 检查数据是否为空\n",
    "        if not data:\n",
    "            print(\"No data found in detected_objects.json.\")\n",
    "            return\n",
    "        \n",
    "        # 获取最新一条记录\n",
    "        latest_entry = data[-1]  # 列表的最后一个元素是最新记录\n",
    "        \n",
    "        # 提取 force 值\n",
    "        force = latest_entry.get(\"force\")\n",
    "        \n",
    "        # 打印 force 值\n",
    "        if force is not None:\n",
    "            print(f\"Latest force value: {force}\")\n",
    "            \n",
    "        else:\n",
    "            print(\"No force value found in the latest entry.\")\n",
    "    \n",
    "    except FileNotFoundError:\n",
    "        print(\"File detected_objects.json not found.\")\n",
    "    except json.JSONDecodeError:\n",
    "        print(\"Invalid JSON format in detected_objects.json.\")\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "\n",
    "# 调用函数打印最新 force 值\n",
    "print_latest_force()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8f4ca7df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "print(force)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
